{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9bc18a01",
   "metadata": {},
   "source": [
    "# Trajectory Intention Classifiers and Novelty Detector script"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57544f87",
   "metadata": {},
   "source": [
    "This script provides step-step procedure to predict the trajectory intention classes of drones. First, the data pre-processing to transform the data into sub-trajectory features in accordance with a pre-selected window length is provided. Then, the data is splited into training, validation and testing datasets to train and test our models. Here, we test several neural models for classification and trajectory reconstruction. \n",
    "The models used for classification are:\n",
    "1. Random Forest (Baseline)\n",
    "2. LSTM: Long Short Term Memory\n",
    "3. GRU: Gated Recurrent Unit\n",
    "4. CBLSTM: Convolutional Biditectional-LSTM\n",
    "5. CBLSTMA: CBLSTM with Attention\n",
    "6. CNN: Convolutional Neural Network\n",
    "7. CNNA: CNN with Attention\n",
    "\n",
    "The models used for reconstruction are:\n",
    "1. LSTM Autoencoder\n",
    "2. Convolutional Autoencoder\n",
    "3. CLSTM Autoencoder\n",
    "\n",
    "The final hybrid model joins both models with\n",
    "1. Classifier - CBLSTMA\n",
    "2. Reconstruction- LSTM Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "destroyed-cheese",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "\n",
    "# Import Packages from our Framework\n",
    "from Framework.DataGeneration.DataPreprocessing import Preprocessing\n",
    "from Framework.DataGeneration.Standardiser import TrajectoryStandardiser\n",
    "from Framework.HybridClassifier.Visualization import Results\n",
    "from Framework.HybridClassifier.RandomForest_Classifier import RandomForest\n",
    "from Framework.HybridClassifier.LSTM_Classifier import LSTM_Network\n",
    "from Framework.HybridClassifier.GRU_Classifier import GRU_Network\n",
    "from Framework.HybridClassifier.ConvLSTM_Classifier import CLSTM_Network\n",
    "from Framework.HybridClassifier.Convolutional_Classifier import Conv_Network\n",
    "from Framework.HybridClassifier.Transformer_Classifier import Transformer_Network\n",
    "from Framework.HybridClassifier.CLSTM_Attention_Classifier import CLSTMA_Network\n",
    "from Framework.HybridClassifier.LSTM_Autoencoder import LSTM_Autoencoder\n",
    "from Framework.HybridClassifier.Convolutional_Autoencoder import Convolutional_Autoencoder\n",
    "from Framework.HybridClassifier.Convolutional_Classifier_Autoencoder import Conv_AE_Classifier\n",
    "from Framework.HybridClassifier.CLSTM_Autoencoder import CLSTM_AE\n",
    "\n",
    "from datetime import datetime\n",
    "from time import time\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "religious-supplement",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set random seeds - ensure consistent results\n",
    "from numpy.random import seed\n",
    "seed(12)\n",
    "from tensorflow.random import set_seed\n",
    "set_seed(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amber-concord",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For pretty visualisations of the plots\n",
    "sns.set_style('white')\n",
    "plt.rcParams[\"font.family\"] = \"Times New Roman\"\n",
    "plt.rcParams['text.usetex'] = True\n",
    "plt.rc('xtick', labelsize = 16) \n",
    "plt.rc('ytick', labelsize = 16)\n",
    "plt.rcParams['font.size'] = 16 \n",
    "plt.rcParams['lines.linewidth'] = 2\n",
    "plt.rc('savefig', dpi=300)\n",
    "plt.rc('axes', titlesize = 16, labelsize = 16)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "productive-function",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get project path and set data directory for notebook\n",
    "PROJECT_PATH = os.getcwd()\n",
    "\n",
    "DATA_DIR = os.path.join(PROJECT_PATH, 'ResearchData/simulated_measurements')\n",
    "DEST_FOLDER = os.path.join(PROJECT_PATH,'FinalModels/Classification')\n",
    "isExist = os.path.exists(DEST_FOLDER)\n",
    "if not isExist:\n",
    "    # Create a new directory because it does not exist\n",
    "    os.makedirs(DEST_FOLDER)\n",
    "    print(\"The new directory is created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "given-consideration",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define intent classes used in this modelling\n",
    "CLASSES = ['mapping_flight', 'package_delivery', \n",
    "           'perimeter_flight', 'point_point_flight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "silver-dubai",
   "metadata": {},
   "outputs": [],
   "source": [
    "# final dataframe to store all modelling results\n",
    "final_results_df = pd.DataFrame()\n",
    "\n",
    "# also store final hybrid model results (including recons)\n",
    "final_hybrid_results_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d84e1f5",
   "metadata": {},
   "source": [
    "# Data Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe6c552",
   "metadata": {},
   "source": [
    "## Preprocessing strategy\n",
    "\n",
    "$\\bullet$ Load every flight trajectory track, split into sub-trajectories of equal window length, and build input feature tensor with associated labels.\n",
    "\n",
    "$\\bullet$ Concatenate all flights together in this way, into a unified dataset of input features with associated labels.\n",
    "\n",
    "$\\bullet$ Create a training and test split, so that the original trajectories (from which the sub-trajectories are taken) are unique between each split. Basically, we don't want to be predicting flights already seen (or partially seen) within the training data, for better estimations of generalisation performance.\n",
    "\n",
    "$\\bullet$ Center Cartesian coordinates of all sub-trajectories so that the first instance starts at $(0, 0, 0)$.\n",
    "\n",
    "$\\bullet$ Standardise numerical features so that they are z-scaled using the mean and standard deviation of the entire training set.\n",
    "\n",
    "$\\bullet$ Label encode uav_type feature to 0 for 'LSS' and 1 for 'Fixed-Wing'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worldwide-conflict",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define tracking features to use within our modelling for classification\n",
    "KEEP_COLS = ['est_x', 'est_y', 'est_z', 'est_vel_x', 'est_vel_y', 'est_vel_z',\n",
    "             'uav_type']\n",
    "\n",
    "Preprocessor = Preprocessing()\n",
    "Plots = Results()\n",
    "\n",
    "# set uav_type idx below (incl zero index)\n",
    "UAV_TYPE_IDX = 6\n",
    "\n",
    "# Window size 8, 16, 32, 64\n",
    "WINDOW_SIZE = 8 # random seed data split=12\n",
    "\n",
    "# new window every 50% into old window\n",
    "if WINDOW_SIZE < 64:\n",
    "    OVERLAP_FACTOR = 2 # use for windows 8, 16 & 32\n",
    "else:\n",
    "    OVERLAP_FACTOR = 4 # use for longer sequences (64)\n",
    "\n",
    "# define encoding mappers for our categorical features\n",
    "UAV_TYPE_MAP = {'LSS' : 0, \n",
    "                'Fixed-Wing' : 1}\n",
    "\n",
    "UAV_INTENT_MAP = {'mapping_flight' : 0, \n",
    "                  'package_delivery' : 1,\n",
    "                  'perimeter_flight' : 2, \n",
    "                  'point_point_flight' : 3}\n",
    "\n",
    "ID_TO_INTENT_MAP = {v:k for k,v in UAV_INTENT_MAP.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "broken-turner",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate sub-trajectories based on the proposed window size\n",
    "\n",
    "X0 = []\n",
    "y0 = []\n",
    "flight_refs0 = []\n",
    "\n",
    "# iterate each class and generate sub-trajectories for flights\n",
    "for class_name in tqdm(CLASSES):\n",
    "    cls_trajs, cls_labels, cls_refs = Preprocessor.get_class_trajectories(class_name, \n",
    "                                                                           DATA_DIR, \n",
    "                                                                           KEEP_COLS, \n",
    "                                                                           WINDOW_SIZE,\n",
    "                                                                           OVERLAP_FACTOR)\n",
    "    X0.append(cls_trajs)\n",
    "    y0.append(cls_labels)\n",
    "    flight_refs0.append(cls_refs)\n",
    "\n",
    "# convert overall results into numpy arrays\n",
    "X0 = np.concatenate(X0)\n",
    "y0 = np.concatenate(y0)\n",
    "flight_refs0 = np.concatenate(flight_refs0)\n",
    "print(f\"X shape: {X0.shape} \\ny shape: {y0.shape}\\nFlight refs: {flight_refs0.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "natural-aggregate",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assess number trajectories for each label and plot\n",
    "cls_counts = np.unique(y0, return_counts=True)\n",
    "\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.bar(x=cls_counts[0], height=cls_counts[1], color=['tab:blue', 'tab:green',\n",
    "                                                      'tab:orange', 'tab:red'])\n",
    "plt.title(\"Trajectory Intention Class Counts\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "productive-design",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove outliers from the trajectories in accordance with a threshold\n",
    "ANOMALOUS_THRESHOLD = 11000\n",
    "X, y, flight_refs = Preprocessor.OutliersRemoval(UAV_TYPE_IDX, X0, y0, flight_refs0, ANOMALOUS_THRESHOLD)\n",
    "print(f\"X shape: {X.shape} \\ny shape: {y.shape}\\nFlight refs: {flight_refs.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "german-copper",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train, validation and test split to create the training, validation and test sets\n",
    "random_seed = 12\n",
    "test_size = 0.10\n",
    "val_size = 0.20\n",
    "\n",
    "(X_train, y_train, X_test, y_test, X_val, y_val, \n",
    " train_flight_refs, val_flight_refs, test_flight_refs) = Preprocessor.Train_Val_Test_Split(X,\n",
    "                                                                                           y,\n",
    "                                                                                           flight_refs,\n",
    "                                                                                           random_state = random_seed,\n",
    "                                                                                           test_size = test_size,\n",
    "                                                                                           val_size = val_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "balanced-harvey",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assess number trajectories for each label and plot\n",
    "trg_cls_counts = np.unique(y_train, return_counts=True)\n",
    "ticks = [x for x in range(len(trg_cls_counts[0]))]\n",
    "\n",
    "fig, ax = plt.subplots(1,3, figsize=(14,4))\n",
    "ax[0].bar(x=trg_cls_counts[0], height=trg_cls_counts[1], \n",
    "          color=['tab:blue', 'tab:green', 'tab:orange', 'tab:red'])\n",
    "ax[0].set_title(\"Class counts (Training)\", weight=\"bold\")\n",
    "ax[0].set_xticks(ticks=ticks, labels=trg_cls_counts[0], \n",
    "                 rotation=45, ha='right')\n",
    "\n",
    "# assess number trajectories for each label and plot\n",
    "val_cls_counts = np.unique(y_val, return_counts=True)\n",
    "ax[1].bar(x=val_cls_counts[0], height=val_cls_counts[1], \n",
    "          color=['tab:blue', 'tab:green', 'tab:orange', 'tab:red'])\n",
    "ax[1].set_title(\"Class counts (Validation)\")\n",
    "ax[1].set_xticks(ticks=ticks, labels=val_cls_counts[0], \n",
    "                 rotation=45, ha='right')\n",
    "\n",
    "# assess number trajectories for each label and plot\n",
    "test_cls_counts = np.unique(y_test, return_counts=True)\n",
    "ax[2].bar(x=test_cls_counts[0], height=test_cls_counts[1], \n",
    "          color=['tab:blue', 'tab:green', 'tab:orange', 'tab:red'])\n",
    "ax[2].set_title(\"Class counts (Test)\")\n",
    "ax[2].set_xticks(ticks=ticks, labels=test_cls_counts[0], \n",
    "                 rotation=45, ha='right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "438d70e9",
   "metadata": {},
   "source": [
    "## Data Standardisation\n",
    "\n",
    "\n",
    "We also need to standardise our features so that they are scaled appropriately for our modelling later on. To do this, we'll use the means and standard deviations for each feature across all timesteps to standardise each feature to have approximately zero mean and 1 standard deviation. This will only be approximate however, given the time-series nature of the trajectories, which makes standardising effectively more complicated.\n",
    "\n",
    "Note that our standardiser object below will return two sets of features:\n",
    "\n",
    "$\\bullet$ Trajectory features: these are multivariate time-series features of target track features for each sub-trajectory.\n",
    "\n",
    "$\\bullet$ Summary (meta) features: these summarise the sub-trajectory using means, standard deviations, min and max point-based (row for each label) features.\n",
    "\n",
    "Within this classification work, we only use the first set of features (trajectory time-series). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "veterinary-scottish",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate our scaler and fit_tranform training, transform test\n",
    "standardiser = TrajectoryStandardiser(num_upper_idx=UAV_TYPE_IDX, \n",
    "                        cat_idx=[UAV_TYPE_IDX],\n",
    "                        cat_mappers=[UAV_TYPE_MAP])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "applicable-attraction",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get standardised sequences and categorical feats\n",
    "X_train_std, X_train_meta = standardiser.fit_transform(X_train)\n",
    "X_val_std, X_val_meta = standardiser.transform(X_val)\n",
    "X_test_std, X_test_meta = standardiser.transform(X_test)\n",
    "print(f\"Training: \\n - Seqs: {X_train_std.shape}\\n - Meta: {X_train_meta.shape}\")\n",
    "print(f\"\\nValidation: \\n - Seqs: {X_val_std.shape}\\n - Meta: {X_val_meta.shape}\")\n",
    "print(f\"\\nTest: \\n - Seqs: {X_test_std.shape}\\n - Meta: {X_test_meta.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adjustable-dubai",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the training data possess aproximately mean zero\n",
    "X_train_std[:, :UAV_TYPE_IDX, :].astype('float').mean(axis=(2,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "muslim-secondary",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the training data possess standard deviation one\n",
    "X_train_std[:, :UAV_TYPE_IDX, :].astype('float').std(axis=(2,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mysterious-guard",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gives the type of UAV that we are working with\n",
    "uav_id_to_type = {v:k for k,v in UAV_TYPE_MAP.items()}\n",
    "uav_id_to_type[np.argmax(X_train_meta[:, :2])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "numerous-bandwidth",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the real-trajectory and the processed trajectory\n",
    "ex_idx = 6000\n",
    "ex_uav_type = uav_id_to_type[np.argmax(X_train_meta[:, :2])]\n",
    "fig, ax = plt.subplots(1,2, figsize=(12,4))\n",
    "ax[0].scatter(X_train[ex_idx, 0, :], X_train[ex_idx, 1, :])\n",
    "ax[0].plot(X_train[ex_idx, 0, :], X_train[ex_idx, 1, :], \n",
    "           alpha=0.3)\n",
    "ax[0].scatter(X_train[ex_idx, 0, 0], X_train[ex_idx, 1, 0],\n",
    "              label='Start', marker='*', color='tab:green', s=200)\n",
    "ax[0].set_title(f\"Sub-Traj ({y_train[ex_idx]})\\nUAV: {ex_uav_type}\")\n",
    "ax[0].set_xlabel('x', weight='bold')\n",
    "ax[0].set_ylabel('y', weight='bold')\n",
    "ax[0].grid(0.5)\n",
    "\n",
    "ax[1].scatter(X_train_std[ex_idx, 0, :], X_train_std[ex_idx, 1, :])\n",
    "ax[1].plot(X_train_std[ex_idx, 0, :], X_train_std[ex_idx, 1, :], \n",
    "           alpha=0.3)\n",
    "ax[1].scatter(X_train_std[ex_idx, 0, 0], X_train_std[ex_idx, 1, 0],\n",
    "              label='Start', marker='*', color='tab:green', s=200)\n",
    "ax[1].set_title(f\"Re-Centred Sub-Traj ({y_train[ex_idx]})\\nUAV: {ex_uav_type}\")\n",
    "ax[1].set_xlabel('x', weight='bold')\n",
    "ax[1].set_ylabel('y', weight='bold')\n",
    "ax[1].grid(0.5)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "parental-honor",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the labels of the trajectory intention classes\n",
    "CLASS_MAPPINGS = {'mapping_flight' : 0,\n",
    "                  'package_delivery' : 1,\n",
    "                  'perimeter_flight' : 2,\n",
    "                  'point_point_flight' : 3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aware-description",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get one hot encoded labels\n",
    "y_train_oh = standardiser.preprocess_labels(y_train, CLASS_MAPPINGS)\n",
    "y_val_oh = standardiser.preprocess_labels(y_val, CLASS_MAPPINGS)\n",
    "y_test_oh = standardiser.preprocess_labels(y_test, CLASS_MAPPINGS)\n",
    "y_train_oh.shape, y_val_oh.shape, y_test_oh.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acting-jurisdiction",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we'll also get normal encoded labels too, since they will be useful\n",
    "# for evaluation of our results later\n",
    "y_train_enc = standardiser.preprocess_labels(y_train, CLASS_MAPPINGS, one_hot=False)\n",
    "y_val_enc = standardiser.preprocess_labels(y_val, CLASS_MAPPINGS, one_hot=False)\n",
    "y_test_enc = standardiser.preprocess_labels(y_test, CLASS_MAPPINGS, one_hot=False)\n",
    "y_train_enc.shape, y_val_enc.shape, y_test_enc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compound-caution",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Final Train features: {X_train_std.shape}\\nTrain labels: {y_train_oh.shape}\")\n",
    "print(f\"\\nFinal Val features: {X_val_std.shape}\\nVal labels: {y_val_oh.shape}\")\n",
    "print(f\"\\nFinal Test features: {X_test_std.shape}\\nTest labels: {y_test_oh.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57da8d80",
   "metadata": {},
   "source": [
    "## Random Forest (Baseline)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f86c5af",
   "metadata": {},
   "source": [
    "Before using Deep Learning methods, we'll make a relatively simple baseline, from which the performance of more complex models can be assessed.\n",
    "\n",
    "We test a Random Forest classifier to make predictions of the intent class based on generated features from the sub-trajectory inputs. Since this model is not sequential (it only supports single point inputs), we need to take the sub-trajectory sequences and process them into a simplified format appropriate for this model. We'll simply generate a series of features from the given input sequences, which typically might include mean values, max / max values, standard deviation and others point-based summary features. This is the method employed by many classical approaches to trajectory classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "parliamentary-binary",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train_sim_std = standardiser.obtain_trajectory_features(X_train_std)\n",
    "X_val_sim_std = standardiser.obtain_trajectory_features(X_val_std)\n",
    "X_test_sim_std = standardiser.obtain_trajectory_features(X_test_std)\n",
    "print(\"Standardised summary data shapes: \")\n",
    "print(f\"Train: {X_train_sim_std.shape} \\nVal: {X_val_sim_std.shape} \\nTest: {X_test_sim_std.shape}\")\n",
    "\n",
    "X_train_sim = standardiser.obtain_trajectory_features(X_train[:, :-1, :])\n",
    "X_val_sim = standardiser.obtain_trajectory_features(X_val[:, :-1, :])\n",
    "X_test_sim = standardiser.obtain_trajectory_features(X_test[:, :-1, :])\n",
    "print(\"\\nOriginal summary data shapes: \")\n",
    "print(f\"Train: {X_train_sim.shape} \\nVal: {X_val_sim.shape} \\nTest: {X_test_sim.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "engaged-worse",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a sunoke random forest classifier\n",
    "RF = RandomForest()\n",
    "\n",
    "# Train the model with the summary features of the sub-trajectories\n",
    "rf_clf, model_results = RF.Random_Forest(X_train_sim_std, y_train_enc,\n",
    "                                 X_val_sim_std, y_val_enc,\n",
    "                                 X_test_sim_std, y_test_enc,\n",
    "                                 WINDOW_SIZE, n_estimators = 20)\n",
    "\n",
    "# Save the final model in a Data Frame for future export\n",
    "final_results_df = final_results_df.append(model_results, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surgical-collins",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the feature importance of each feature in our model\n",
    "classic_col_names = []\n",
    "#for agg in ['mean', 'std', 'max', 'min']:\n",
    "for agg in ['mean']:\n",
    "    for x in KEEP_COLS[:-1]:\n",
    "        classic_col_names.append(f\"{agg}_{x}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "legitimate-roller",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Small function to create a Data Frame of feature importance \n",
    "def feature_importances(rf_model, col_names):\n",
    "    return pd.DataFrame({'columns' : col_names, \n",
    "                         'importance' : rf_model.feature_importances_}\n",
    "                       ).sort_values('importance', ascending=False)\n",
    "\n",
    "# Bar plot visualisation\n",
    "importances = feature_importances(rf_clf, classic_col_names)\n",
    "plt.figure(figsize=(10,5))\n",
    "sns.barplot(x=\"columns\", y=\"importance\", data=importances)\n",
    "plt.ylabel(\"Feature Importances\", weight='bold')\n",
    "plt.xlabel(\"Features\", weight='bold')\n",
    "plt.title(\"Random Forest Feature Importances\", weight='bold')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()\n",
    "print(importances)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "499e424b",
   "metadata": {},
   "source": [
    "## LSTM Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "duplicate-fantasy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the LSTM network using our LSTM_Network class\n",
    "lstm_model = LSTM_Network(epochs = 75, batch_size = 256)\n",
    "lstm_model.LSTM_model(X_train_std).summary()\n",
    "\n",
    "# Train the LSTM classifier\n",
    "lstm_history = lstm_model.train(X_train_std, y_train_oh,\n",
    "                                          X_val_std, y_val_oh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surgical-marina",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the results of the LSTM network\n",
    "Plots.AccLoss(lstm_history)\n",
    "\n",
    "# Results under the validation and testing sets\n",
    "model_results = lstm_model.prediction(X_val_std, y_val_enc,\n",
    "                                      X_test_std, y_test_enc,\n",
    "                                      WINDOW_SIZE)\n",
    "\n",
    "# Store the final results for future export\n",
    "final_results_df = final_results_df.append(model_results, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b09e84a7",
   "metadata": {},
   "source": [
    "## GRU Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intense-election",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the GRU network using our GRU Network class\n",
    "gru_model = GRU_Network(epochs = 75, batch_size = 256)\n",
    "gru_model.GRU_model(X_train_std).summary()\n",
    "\n",
    "# Train the GRU classifier\n",
    "gru_history = gru_model.train(X_train_std, y_train_oh,\n",
    "                                          X_val_std, y_val_oh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "declared-performer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the results of the LSTM Network\n",
    "Plots.AccLoss(gru_history)\n",
    "\n",
    "# Results under the validation and testing sets\n",
    "model_results = gru_model.prediction(X_val_std, y_val_enc,\n",
    "                      X_test_std, y_test_enc,\n",
    "                      WINDOW_SIZE)\n",
    "\n",
    "# Store the final results for future export\n",
    "final_results_df = final_results_df.append(model_results, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3de6312",
   "metadata": {},
   "source": [
    "## Convolutional Bidirectional LSTM (CBLSTM) Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prerequisite-comment",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the hyperparameters of the network\n",
    "convlstm_params = {'activation' : 'relu', \n",
    "                   'dense_units' : 64,\n",
    "                   'dense_dropout' : 0.3,\n",
    "                   'rnn_dropout' : 0.3,\n",
    "                   'conv_filters' : 20,\n",
    "                   'kernel_size' : 12,\n",
    "                   'optimizer' : 'adam',\n",
    "                   'bidirectional' : True,\n",
    "                   'lstm_units' : 32,\n",
    "                   'n_classes' : 4,\n",
    "                   'lr' : 5e-4,\n",
    "                  'epochs' : 75,\n",
    "                  'batch_size' : 128}\n",
    "\n",
    "# Instantiate our CLSTM network class with the pre-defined hyperparameters\n",
    "convlstm_model = CLSTM_Network(**convlstm_params)\n",
    "convlstm_model.ConvLSTM_model(X_train_std)\n",
    "\n",
    "# Train our CLSTM/CBLSTM network \n",
    "convlstm_history = convlstm_model.train(X_train_std, y_train_oh, \n",
    "                                        X_val_std, y_val_oh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "subtle-delhi",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the results of the CLSTM/CBLSTM network\n",
    "Plots.AccLoss(convlstm_history)\n",
    "\n",
    "# Results under the validation and testing sets\n",
    "model_results = convlstm_model.prediction(X_val_std, y_val_enc,\n",
    "                      X_test_std, y_test_enc,\n",
    "                      WINDOW_SIZE)\n",
    "\n",
    "# Store the final result for testing\n",
    "final_results_df = final_results_df.append(model_results, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "139ca847",
   "metadata": {},
   "source": [
    "## CNN/CNNA Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incident-signal",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameters of the network\n",
    "\n",
    "conv_params = {'activation' : 'swish', \n",
    "               'dense_units' : 64,\n",
    "               'dense_dropout' : 0.4,\n",
    "               'filters' : [32,64],\n",
    "               'kernel_size' : 12,\n",
    "               'optimizer' : 'adam',\n",
    "               'n_classes' : 4,\n",
    "               'lr' : 1e-3,\n",
    "               'attention' : True,\n",
    "               'epochs': 85,\n",
    "               'batch_size': 128\n",
    "              }\n",
    "\n",
    "# Instantiate the CNN/CNNA classifier\n",
    "conv_model = Conv_Network(**conv_params)\n",
    "conv_model.Conv_model(X_train_std).summary()\n",
    "\n",
    "# Train the CNN/CNNA classifier\n",
    "conv_history = conv_model.train(X_train_std, y_train_oh, \n",
    "                                        X_val_std, y_val_oh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "filled-attachment",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the results of the CNN/CNNA classifier\n",
    "Plots.AccLoss(conv_history)\n",
    "\n",
    "# Results under the validation and testing sets\n",
    "model_results = conv_model.prediction(X_val_std, y_val_enc,\n",
    "                      X_test_std, y_test_enc,\n",
    "                      WINDOW_SIZE)\n",
    "\n",
    "# Store the results for future export\n",
    "final_results_df = final_results_df.append(model_results, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d6e336",
   "metadata": {},
   "source": [
    "## Attention-based Transformer classifier (not reported) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8eca9db",
   "metadata": {},
   "source": [
    "Warning - this model is computationally intensive and unless running on GPU, will take a very long time. It is not recommended to run this on default CPU, especially on the lower window sizes of 8 and 16."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "passing-banks",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the transformer network class\n",
    "trans_model = Transformer_Network(epochs = 80)\n",
    "trans_model.transformer_dnn_model(X_train_std)\n",
    "\n",
    "# Train the transformer network\n",
    "trans_history = trans_model.train(X_train_std, y_train_oh, \n",
    "                                        X_val_std, y_val_oh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adult-contract",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the results of the transformer network\n",
    "Plots.AccLoss(trans_history)\n",
    "\n",
    "# Results under validation and testing sets\n",
    "model_results = trans_model.prediction(X_val_std, y_val_enc,\n",
    "                      X_test_std, y_test_enc,\n",
    "                      WINDOW_SIZE)\n",
    "\n",
    "# Store the results for future export\n",
    "final_results_df = final_results_df.append(model_results, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1371da4",
   "metadata": {},
   "source": [
    "The computational requirements for training, along with the poor performance compared to the Conv LSTM and Conv DNN variants, make this model a poor choice.\n",
    "\n",
    "It is possible that with further tweaking, refinements and increased quantities of training data this model could perform significantly better, but even so, the extremely slow inference and training time on CPU makes it a poor choice currently."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "016b94ab",
   "metadata": {},
   "source": [
    "## CLSTM/CBLSTM with Attention Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inappropriate-spelling",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the hyperparameters of the network\n",
    "convlstm_att_params = {'activation' : 'swish',\n",
    "                       'dense_units' : 64,\n",
    "                       'dense_dropout' : 0.4,\n",
    "                       'rnn_dropout' : 0.4,\n",
    "                       'conv_filters' : 32,\n",
    "                       'kernel_size' : 12,\n",
    "                       'lr' : 5e-3,\n",
    "                       'bidirectional' : True,\n",
    "                       'lstm_units' : 20,\n",
    "                       'n_classes' : 4,\n",
    "                       'lr' : 5e-4}\n",
    "\n",
    "# Instantiate the CLSTMA/CBLSTMA network\n",
    "clstma_model = CLSTMA_Network(epochs = 100)\n",
    "clstma_model.ConvLSTM_Attention_model(X_train_std)\n",
    "\n",
    "# Train the CLSTMA/CBLSTMA network\n",
    "clstma_history = clstma_model.train(X_train_std, y_train_oh, \n",
    "                                        X_val_std, y_val_oh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "modern-jacksonville",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the results of the CLSTMA/CBLSTMA network\n",
    "Plots.AccLoss(clstma_history)\n",
    "\n",
    "# Results under validation and testing sets\n",
    "model_results = clstma_model.prediction(X_val_std, y_val_enc,\n",
    "                      X_test_std, y_test_enc,\n",
    "                      WINDOW_SIZE)\n",
    "\n",
    "# Store the final results for future export\n",
    "final_results_df = final_results_df.append(model_results, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "075bd9ab",
   "metadata": {},
   "source": [
    "# Novelty Detection (Autoencoder - Based Reconstruction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b22fdbab",
   "metadata": {},
   "source": [
    "Within this section we'll explore Deep Autoencoders for Novelty Detection. This will allow us to determine whether new data coming in is similar or very different (anomalous) to that known and modelled by the system.\n",
    "\n",
    "In effect, if new data coming in is flagged as anomalous, then this might correspond to a flight with unknown intent (does not fit clearly into one of our pre-defined categories). This could be useful, since we could then follow-up with a generic heuristic or modelling strategy to determine the future occupied space of that UAV (e.g. a generic particle filter with predictions n steps into the future)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad158615",
   "metadata": {},
   "source": [
    "## Sequential LSTM Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "polyphonic-blackberry",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the LSTM Autoencoder\n",
    "lstm_ae = LSTM_Autoencoder(epochs = 200)\n",
    "lstm_ae.lstm_autoencoder_model(X_train_std).summary()\n",
    "\n",
    "# Train the LSTM Autoencoder\n",
    "lstm_ae_history = lstm_ae.train(X_train_std, X_val_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "circular-revelation",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot the results of the LSTM Autoencoder \n",
    "Plots.RMSE(lstm_ae_history)\n",
    "\n",
    "# Obtain the reconstructions, mean squared errors, and standard deviations of the training\n",
    "# validation and testing datasets\n",
    "trg_recon, trg_recon_mses, trg_recon_stds = lstm_ae.prediction(X_train_std)\n",
    "val_recon, val_recon_mses, val_recon_stds = lstm_ae.prediction(X_val_std)\n",
    "test_recon, test_recon_mses, test_recon_stds = lstm_ae.prediction(X_test_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brutal-communications",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the results of the autoencoder with unseen trajectories that do not match with our intent classes\n",
    "\n",
    "# Preprocess the unseen trajectories\n",
    "X_unseen, y_unseen, refs_unseen = Preprocessor.get_class_trajectories('other', \n",
    "                                                                      DATA_DIR, \n",
    "                                                                      KEEP_COLS, \n",
    "                                                                      WINDOW_SIZE,\n",
    "                                                                      OVERLAP_FACTOR)\n",
    "\n",
    "print(f\"X shape: {X_unseen.shape} \\ny shape: {y_unseen.shape}\\n\")\n",
    "\n",
    "# preprocess unseen data, get recons using our autoencoder\n",
    "X_unseen_std, X_unseen_meta = standardiser.transform(X_unseen)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "medium-program",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results of the LSTM autoencoder under the unseen trajectories\n",
    "unseen_recons, unseen_recon_mses, unseen_recon_stds  = lstm_ae.prediction(X_unseen_std)\n",
    "for idx in range(11):\n",
    "    Plots.plot_recon_results(idx, X_unseen_std, y_unseen, unseen_recons, \n",
    "                       trg_recon_mses, val_recon_mses, figsize=(12,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e73a16a",
   "metadata": {},
   "source": [
    "## Sequential CNN Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial-conjunction",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the convolutional autoencoder class\n",
    "conv_ae = Convolutional_Autoencoder(epochs = 200)\n",
    "conv_ae.conv_autoencoder_model(X_train_std).summary()\n",
    "\n",
    "# Train the convolutional autoencoder\n",
    "conv_ae_history = conv_ae.train(X_train_std, X_val_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brave-compact",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results of the convolutional autoencoder\n",
    "Plots.MSE(conv_ae_history)\n",
    "\n",
    "# Obtain the reconstructions, mean squared errors, and standard deviations of the training\n",
    "# validation and testing datasets\n",
    "trg_conv_ae_recon, trg_conv_ae_recon_mses, trg_conv_ae_recon_stds = conv_ae.prediction(X_train_std)\n",
    "val_conv_ae_recon, val_conv_ae_recon_mses, val_conv_ae_recon_stds = conv_ae.prediction(X_val_std)\n",
    "test_conv_ae_recon, test_conv_ae_recon_mses, test_conv_ae_recon_stds = conv_ae.prediction(X_test_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "honey-nigeria",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results of the CNN autoencoder under the unseen trajectories\n",
    "unseen_recons, unseen_error_mean, unseen_error_stds  = conv_ae.prediction(X_unseen_std)\n",
    "\n",
    "print(f\"Unseen (other) mean feature MSE: {unseen_error_mean}\")\n",
    "print(f\"Times larger than training mean: {unseen_error_mean / trg_conv_ae_recon_mses}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "947d6acc",
   "metadata": {},
   "source": [
    "# Combined Autoencoder Novelty Detector and Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "298a0c29",
   "metadata": {},
   "source": [
    "We'll create a hybrid architecture that performs both novelty detection and trajectory classification. This will build on all of the techniques covered above, designed into a unified classification / novelty detector architecture.\n",
    "\n",
    "Novelty detection will be performed using an Autoencoder component of the network, whilst trajectory classification will be performed using a custom dense output from the encoder part of the autoencoder.\n",
    "\n",
    "The benefit of such an architecture is that it means we have a single model that performs both novelty detection and classification, rather than wastefully having two large DNNs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a26d0412",
   "metadata": {},
   "source": [
    "## Convolutional Classifier & Autoencoder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fluid-projector",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the convolutional classifier & autoencoder novelty detector\n",
    "conv_ae_class = Conv_AE_Classifier(epochs = 75)\n",
    "conv_ae_class.Conv_AE_Classifier(X_train_std).summary()\n",
    "\n",
    "# Train the classifier & autoencoder novelty detector\n",
    "conv_ae_class_history = conv_ae_class.train(X_train_std, y_train_oh, X_val_std, y_val_oh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "curious-trail",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results of both the classifier and novelty detector\n",
    "Plots.Custom_AccLoss(conv_ae_class_history)\n",
    "\n",
    "# Obtain the reconstructions, mean squared errors, and standard deviations of the training\n",
    "# validation, testing and unseen datasets\n",
    "trg_preds, trg_recons, trg_recon_mse, trg_recon_std = conv_ae_class.prediction(X_train_std, y_train_enc)\n",
    "val_preds, val_recons, val_recon_mse, val_recon_std = conv_ae_class.prediction(X_val_std, y_val_enc)\n",
    "test_preds, test_recons, test_recon_mse, test_recon_std = conv_ae_class.prediction(X_test_std, y_test_enc)\n",
    "unseen_preds, unseen_recons, unseen_recon_mse, unseen_recon_std = conv_ae_class.predictionUnseen(X_unseen_std)\n",
    "print(f\"Unseen MSE factor relative to training: {unseen_recon_mse/trg_recon_mse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff7da01",
   "metadata": {},
   "source": [
    "## CLSTM/CBLSTMA & Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spatial-press",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the hyperparameters of the CLSTM/CBLSTMA & LSTM Autoencoder\n",
    "clstm_ae_params = {'activation' : 'swish',\n",
    "                      'dense_units' : 64,\n",
    "                      'dense_dropout' : 0.4,\n",
    "                      'rnn_dropout' : 0.4,\n",
    "                      'conv_filters' : [32],\n",
    "                      'kernel_size' : 12,\n",
    "                      'lr' : 1e-3,\n",
    "                      'bidirectional' : True,\n",
    "                      'attention' : True,\n",
    "                      'lstm_units' : [20, 20],\n",
    "                      'n_classes' : 4,\n",
    "                      'clf_model_weight' : 0.95,\n",
    "                      'codings_size' : 16,\n",
    "                      'epochs': 150,\n",
    "                      'batch_size': 128}\n",
    "\n",
    "# Instantiate the CLSTM/CBLSTMA & Autoencoder class\n",
    "clstm_ae = CLSTM_AE(**clstm_ae_params)\n",
    "clstm_ae.CLSTM_AE(X_train_std).summary()\n",
    "\n",
    "# Train the CBLSTMA & LSTM Autoencoder network\n",
    "clstm_ae_history = clstm_ae.train(X_train_std, y_train_oh, X_val_std, y_val_oh, y_train_enc, WINDOW_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ready-stevens",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results for validation and testing sets for classification and reconstruction\n",
    "(model_results, val_preds, \n",
    " val_recons, test_preds, test_recons,\n",
    " trg_recon_mse, val_recon_mse, test_recon_mse) = clstm_ae.prediction(X_val_std, y_val_enc,\n",
    "                                                                                  X_test_std, y_test_enc,\n",
    "                                                                                  WINDOW_SIZE)\n",
    "\n",
    "# Store the results for future export\n",
    "final_results_df = final_results_df.append(model_results, ignore_index=True)\n",
    "ae_hybrid_results = model_results.copy()\n",
    "ae_hybrid_results['Train Recon MSE'] = trg_recon_mse\n",
    "ae_hybrid_results['Val Recon MSE'] = val_recon_mse\n",
    "ae_hybrid_results['Test Recon MSE'] = test_recon_mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "valid-dispute",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reconstructions under unseen trajectories\n",
    "unseen_preds, unseen_recons, unseen_recon_mse = clstm_ae.predictionUnseen(X_unseen_std)\n",
    "ae_hybrid_results['Other Recon MSE'] = unseen_recon_mse\n",
    "\n",
    "# Store the reconstruction results for future export\n",
    "final_hybrid_results_df = final_hybrid_results_df.append(ae_hybrid_results, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "needed-stereo",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot some unseen sample trajectories to observe the performance of the hybrid classifier\n",
    "random_idx = np.random.choice(X_unseen_std.shape[0], 10, replace=False)\n",
    "index = 0\n",
    "for idx in random_idx:\n",
    "    index += 1\n",
    "    Plots.plot_classification_results(idx, index, X_unseen, X_unseen_std, y_unseen,\n",
    "                                      unseen_preds, unseen_recons,\n",
    "                                      trg_recon_mse, val_recon_mse,\n",
    "                                      ID_TO_INTENT_MAP, UAV_INTENT_MAP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "typical-minority",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot sample trajectories from the testing dataset to observe the performance of the hybrid classifier\n",
    "random_idx = np.random.choice(X_test_std.shape[0], 10, replace=False)\n",
    "for idx in random_idx:\n",
    "    index += 1\n",
    "    Plots.plot_classification_results(idx, index, X_test, X_test_std, y_test,\n",
    "                                      test_preds, test_recons,\n",
    "                                      trg_recon_mse, val_recon_mse,\n",
    "                                      ID_TO_INTENT_MAP, UAV_INTENT_MAP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ranging-petersburg",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets also save the final model results \n",
    "now = datetime.now()\n",
    "current_date = now.strftime(\"%Y%m%d\")\n",
    "final_results_df.to_excel(f\"{current_date}-final_clf_results.xlsx\", index=False)\n",
    "final_hybrid_results_df.to_excel(f\"{current_date}-final_hybrid_results.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stretch-castle",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model as .h5 file\n",
    "model_name = f\"clstm_ae_window_{WINDOW_SIZE}.h5\"\n",
    "model_savepath = os.path.join(DEST_FOLDER, model_name)\n",
    "clstm_ae.save(model_savepath)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
